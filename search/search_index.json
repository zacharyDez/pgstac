{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p> <p>PostgreSQL schema and functions for Spatio-Temporal Asset Catalog (STAC)</p> </p> <p> </p> <p>Documentation: stac-utils.github.io/pgstac/</p> <p>Source Code: stac-utils/pgstac</p> <p>PgSTAC is a set of SQL function and schema to build highly performant database for Spatio-Temporal Asset Catalog (STAC). The project also provide pypgstac python module to help with the database migration and documents ingestion (collections and items).</p> <p>PgSTAC provides functionality for STAC Filters and CQL2 search along with utilities to help manage indexing and partitioning of STAC Collections and Items.</p> <p>PgSTAC is used in production to scale to hundreds of millions of STAC items. PgSTAC implements core data models and functions to provide a STAC API from a PostgreSQL database. As PgSTAC is fully within the database, it does not provide an HTTP facing API. The Stac FastAPI PgSTAC backend and Franklin can be used to expose a PgSTAC catalog. It is also possible to integrate PgSTAC with any other language that has PostgreSQL drivers.</p> <p>PgSTAC Documentation: stac-utils.github.io/pgstac/pgstac</p> <p>pyPgSTAC Documentation: stac-utils.github.io/pgstac/pypgstac</p>"},{"location":"#project-structure","title":"Project structure","text":"<pre><code>/\n \u251c\u2500\u2500 src/pypgstac           - pyPgSTAC python module\n \u251c\u2500\u2500 src/pypgstac/tests/    - pyPgSTAC tests\n \u251c\u2500\u2500 scripts/               - scripts to set up the environment, create migrations, and run tests\n \u251c\u2500\u2500 src/pgstac/sql/        - PgSTAC SQL code\n \u251c\u2500\u2500 src/pgstac/migrations/ - Migrations for incremental upgrades\n \u2514\u2500\u2500 src/pgstac/tests/      - test suite\n</code></pre>"},{"location":"#contribution-development","title":"Contribution &amp; Development","text":"<p>See CONTRIBUTING.md</p>"},{"location":"#license","title":"License","text":"<p>See LICENSE</p>"},{"location":"#authors","title":"Authors","text":"<p>See contributors for a listing of individual contributors.</p>"},{"location":"#changes","title":"Changes","text":"<p>See CHANGELOG.md.</p>"},{"location":"contributing/","title":"Development - Contributing","text":"<p>PGStac uses a dockerized development environment. However, it still needs a local install of pypgstac to allow an editable install inside the docker container. This is installed automatically if you have set up a virtual environment for the project. Otherwise you'll need to install a local copy yourself by running <code>scripts/install</code>.</p> <p>To build the docker images and set up the test database, use:</p> <pre><code>scripts/setup\n</code></pre> <p>To bring up the development database: <pre><code>scripts/server\n</code></pre></p> <p>To run tests, use: <pre><code>scripts/test\n</code></pre></p> <p>To rebuild docker images: <pre><code>scripts/update\n</code></pre></p> <p>To drop into a console, use <pre><code>scripts/console\n</code></pre></p> <p>To drop into a psql console on the database container, use: <pre><code>scripts/console --db\n</code></pre></p> <p>To run migrations on the development database, use <pre><code>scripts/migrate\n</code></pre></p> <p>To stage code and configurations and create template migrations for a version release, use <pre><code>scripts/stageversion [version]\n</code></pre></p> <p>Examples: <pre><code>scripts/stageversion 0.2.8\n</code></pre></p> <p>This will create a base migration for the new version and will create incremental migrations between any existing base migrations. The incremental migrations that are automatically generated by this script will have the extension \".staged\" on the file. You must manually review (and make any modifications necessary) this file and remove the \".staged\" extension to enable the migration.</p>"},{"location":"contributing/#making-changes-to-sql","title":"Making Changes to SQL","text":"<p>All changes to SQL should only be made in the <code>/src/pgstac/sql</code> directory. SQL Files will be run in alphabetical order.</p>"},{"location":"contributing/#adding-tests","title":"Adding Tests","text":"<p>PGStac tests can be written using PGTap or basic SQL output comparisons. Additional testing is available using PyTest in the PyPgSTAC module. Tests can be run using the <code>scripts/test</code> command.</p> <p>PGTap tests can be written using PGTap syntax. Tests should be added to the <code>/src/pgstac/tests/pgtap</code> directory. Any new sql files added to this directory must be added to <code>/src/pgstac/tests/pgtap.sql</code>.</p> <p>The Basic SQL tests will run any file ending in '.sql' in the <code>/src/pgstac/tests/basic</code> directory and will compare the exact results to the corresponding '.sql.out' file.</p> <p>PyPgSTAC tests are located in <code>/src/pypgstac/tests</code>.</p> <p>All tests can be found in tests/pgtap.sql and are run using <code>scripts/test</code></p> <p>Individual tests can be run with any combination of the following flags \"--formatting --basicsql --pgtap --migrations --pypgstac\". If pre-commit is installed, tests will be run on commit based on which files have changed.</p>"},{"location":"contributing/#to-make-a-pr","title":"To make a PR","text":"<p>1) Make any changes. 2) Make sure there are tests if appropriate. 3) Update Changelog using \"### Unreleased\" as the version. 4) Make any changes necessary to the docs. 5) Ensure all tests pass (pre-commit will take care of this if installed and the tests will also run on CI) 6) Create PR against the \"main\" branch.</p>"},{"location":"contributing/#release-process","title":"Release Process","text":"<p>1) Run \"scripts/stageversion VERSION\" (where version is the next version using semantic versioning ie 0.7.0 2) Check the incremental migration created in the /src/pgstac/migrations file with the .staged extension to make sure that the generated SQL looks appropriate. 3) Run the tests against the incremental migrations \"scripts/test --migrations\" 4) Move any \"Unreleased\" changes in the CHANGELOG.md to the new version. 5) Open a PR for the version change. 6) Once the PR has been merged, start the release process. 7) Create a git tag <code>git tag v0.2.8</code> using new version number 8) Push the git tag <code>git push origin v0.2.8</code> 9) The CI process will push pypgstac to PyPi, create a docker image on ghcr.io, and create a release on github.</p>"},{"location":"contributing/#get-involved","title":"Get Involved","text":"<p>Issues and pull requests are more than welcome: github.com/stac-utils/pgstac/issues</p>"},{"location":"pgstac/","title":"PgSTAC","text":"<p>PGDatabase Schema and Functions for Storing and Accessing STAC collections and items in PostgreSQL</p> <p>STAC Client that uses PGStac available in STAC-FastAPI</p> <p>PGStac requires Postgresql&gt;=13 and PostGIS&gt;=3. Best performance will be had using PostGIS&gt;=3.1.</p>"},{"location":"pgstac/#pgstac-settings","title":"PGStac Settings","text":"<p>PGStac installs everything into the pgstac schema in the database. This schema must be in the search_path in the postgresql session while using pgstac.</p>"},{"location":"pgstac/#pgstac-users","title":"PGStac Users","text":"<p>The pgstac_admin role is the owner of all the objects within pgstac and should be used when running things such as migrations.</p> <p>The pgstac_ingest role has read/write privileges on all tables and should be used for data ingest or if using the transactions extension with stac-fastapi-pgstac.</p> <p>The pgstac_read role has read only access to the items and collections, but will still be able to write to the logging tables.</p> <p>You can use the roles either directly and adding a password to them or by granting them to a role you are already using.</p> <p>To use directly: <pre><code>ALTER ROLE pgstac_read LOGIN PASSWORD '&lt;password&gt;';\n</code></pre></p> <p>To grant pgstac permissions to a current postgresql user: <pre><code>GRANT pgstac_read TO &lt;user&gt;;\n</code></pre></p>"},{"location":"pgstac/#pgstac-search-path","title":"PGStac Search Path","text":"<p>The search_path can be set at the database level or role level or by setting within the current session. The search_path is already set if you are directly using one of the pgstac users. If you are not logging in directly as one of the pgstac users, you will need to set the search_path by adding it to the search_path of the user you are using: <pre><code>ALTER ROLE &lt;user&gt; SET SEARCH_PATH TO pgstac, public;\n</code></pre> setting the search_path on the database: <pre><code>ALTER DATABASE &lt;database&gt; set search_path to pgstac, public;\n</code></pre></p> <p>In psycopg the search_path can be set by passing it as a configuration when creating your connection: <pre><code>kwargs={\n    \"options\": \"-c search_path=pgstac,public\"\n}\n</code></pre></p>"},{"location":"pgstac/#pgstac-settings-variables","title":"PGStac Settings Variables","text":"<p>There are additional variables that control the settings used for calculating and displaying context (total row count) for a search, as well as a variable to set the filter language (cql-json or cql-json2). The context is \"off\" by default, and the default filter language is set to \"cql2-json\".</p> <p>Variables can be set either by passing them in via the connection options using your connection library, setting them in the pgstac_settings table or by setting them on the Role that is used to log in to the database.</p> <p>Turning \"context\" on can be very expensive on larger databases. Much of what PGStac does is to optimize the search of items sorted by time where only fewer than 10,000 records are returned at a time. It does this by searching for the data in chunks and is able to \"short circuit\" and return as soon as it has the number of records requested. Calculating the context (the total count for a query) requires a scan of all records that match the query parameters and can take a very long time. Setting \"context\" to auto will use database statistics to estimate the number of rows much more quickly, but for some queries, the estimate may be quite a bit off.</p> <p>Example for updating the pgstac_settings table with a new value: <pre><code>INSERT INTO pgstac_settings (name, value)\nVALUES\n('default-filter-lang', 'cql-json'),\n('context', 'on')\n\nON CONFLICT ON CONSTRAINT pgstac_settings_pkey DO UPDATE SET value = excluded.value;\n</code></pre></p> <p>Alternatively, update the role: <pre><code>ALTER ROLE &lt;username&gt; SET SEARCH_PATH to pgstac, public;\nALTER ROLE &lt;username&gt; SET pgstac.context TO &lt;'on','off','auto'&gt;;\nALTER ROLE &lt;username&gt; SET pgstac.context_estimated_count TO '&lt;number of estimated rows when in auto mode that when an estimated count is less than will trigger a full count&gt;';\nALTER ROLE &lt;username&gt; SET pgstac.context_estimated_cost TO '&lt;estimated query cost from explain when in auto mode that when an estimated cost is less than will trigger a full count&gt;';\nALTER ROLE &lt;username&gt; SET pgstac.context_stats_ttl TO '&lt;an interval string ie \"1 day\" after which pgstac search will force recalculation of it's estimates&gt;&gt;';\n</code></pre></p> <p>The check_pgstac_settings function can be used to check what pgstac settings are being used and to check recommendations for system settings. It takes a single parameter which should be the amount of memory available on the database system. <pre><code>SELECT check_pgstac_settings('16GB');\n</code></pre></p>"},{"location":"pgstac/#runtime-configurations","title":"Runtime Configurations","text":"<p>Runtime configuration of variables can be made with search by passing in configuration in the search json \"conf\" item.</p> <p>Runtime configuration is available for context, context_estimated_count, context_estimated_cost, context_stats_ttl, and nohydrate.</p> <p>The nohydrate conf item returns an unhydrated item bypassing the CPU intensive step of rehydrating data with data from the collection metadata. When using the nohydrate conf, the only fields that are respected in the fields extension are geometry and bbox. <pre><code>SELECT search('{\"conf\":{\"nohydrate\"=true}}');\n</code></pre></p>"},{"location":"pgstac/#pgstac-partitioning","title":"PGStac Partitioning","text":"<p>By default PGStac partitions data by collection (note: this is a change starting with version 0.5.0). Each collection can further be partitioned by either year or month. Partitioning must be set up prior to loading any data! Partitioning can be configured by setting the partition_trunc flag on a collection in the database. <pre><code>UPDATE collections set partition_trunc='month' WHERE id='&lt;collection id&gt;';\n</code></pre></p> <p>In general, you should aim to keep each partition less than a few hundred thousand rows. Further partitioning (ie setting everything to 'month' when not needed to keep the partitions below a few hundred thousand rows) can be detrimental.</p>"},{"location":"pgstac/#pgstac-indexes-queryables","title":"PGStac Indexes / Queryables","text":"<p>By default, PGStac includes indexes on the id, datetime, collection, geometry, and the eo:cloud_cover property. Further indexing can be added for additional properties globally or only on particular collections by modifications to the queryables table.</p> <p>The <code>queryables</code> table controls the indexes that PGStac will build as well as the metadata that is returned from a STAC Queryables endpoint.</p> Column Description Type Example <code>id</code> The id of the queryable bigint[pk] - <code>name</code> The name of the property text <code>eo:cloud_cover</code> <code>collection_ids</code> The collection ids that this queryable applies to text[] <code>{sentinel-2-l2a,landsat-c2-l2,aster-l1t}</code> or <code>NULL</code> <code>definition</code> The queryable definition of the property jsonb <code>{\"title\": \"Cloud Cover\", \"type\": \"number\", \"minimum\": 0, \"maximum\": 100}</code> <code>property_wrapper</code> The wrapper function to use to convert the property to a searchable type text One of <code>to_int</code>, <code>to_float</code>, <code>to_tstz</code>, <code>to_text</code> or <code>NULL</code> <code>property_index_type</code> The index type to use for the property text <code>BTREE</code>, <code>NULL</code> or other valid PostgreSQL index type <p>Each record in the queryables table references a single property but can apply to any number of collections. If the <code>collection_ids</code> field is left as NULL, then that queryable will apply to all collections. There are constraints that allow only a single queryable record to be active per collection. If there is a queryable already set for a property field with collection_ids set to NULL, you will not be able to create a separate queryable entry that applies to that property with a specific collection as pgstac would not then be able to determine which queryable entry to use.</p>"},{"location":"pgstac/#queryable-metadata","title":"Queryable Metadata","text":"<p>When used with stac-fastapi, the metadata returned in the queryables endpoint is determined using the definition field on the <code>queryables</code> table. This is a jsonb field that will be returned as-is in the queryables response. The full queryable response for a collection will be determined by all the <code>queryables</code> records that have a match in <code>collection_ids</code> or have a NULL <code>collection_ids</code>.</p> <p>If two or more collections in your catalog share a property name, but have different definitions (e.g., <code>platform</code> with different enum values), be sure to repeat the property for each collection id, each with a unique <code>definition</code>.</p> <p>There is a utility SQL function that can be used to help populate the <code>queryables</code> table by looking at a sample of data for each collection. This utility can also look to the json schema for STAC extensions defined in the <code>stac_extensions</code> table.</p> <p>The <code>stac_extensions</code> table contains a <code>url</code> field and a <code>content</code> field for each extension that should be introspected to compare for fields. This can either be filled in manually or by using the <code>pypgstac loadextensions</code> command included with pypgstac. This command will look at the <code>stac_extensions</code> attribute in all collections to populate the <code>stac_extensions</code> table, fetching the json content of each extension. If any urls were added manually to the stac_extensions table, it will also populate any records where the content is NULL.</p> <p>Once the <code>stac_extensions</code> table has been filled in, you can run the <code>missing_queryables</code> function either for a single collection:</p> <pre><code>SELECT * FROM missing_queryables('mycollection', 5);\n</code></pre> <p>or for all collections:</p> <pre><code>SELECT * FROM missing_queryables(5);\n</code></pre> <p>The numeric argument is the approximate percent of items that should be sampled to look for fields to include. This function will look for fields in the properties of items that do not already exist in the queryables table for each collection. It will then look to see if there is a field in any definition in the stac_extensions table to populate the definition for the queryable. If no definition was found, it will use the data type of the values for that field in the sample of items to fill in a generic definition with just the field type.</p> <p>In order to populate the queryables table, you can then run the following query. Note we're casting the collection id to a text array:</p> <pre><code>INSERT INTO queryables (collection_ids, name, definition, property_wrapper)\nSELECT array[collection]::text[] as collection_ids, name, definition, property_wrapper\nFROM missing_queryables('mycollection', 5)\n</code></pre> <p>If you run into conflicts due to the unique constraints on collection/name, you may need to create a temp table, make any changes to remove the conflicts, and then INSERT.</p> <pre><code>CREATE TEMP TABLE draft_queryables AS SELECT * FROM missing_queryables(5);\n</code></pre> <p>Make any edits to that table or the existing queryables, then:</p> <pre><code>INSERT INTO queryables (collection_ids, name, definition, property_wrapper) SELECT * FROM draft_queryables;\n</code></pre>"},{"location":"pgstac/#indexing","title":"Indexing","text":"<p>The <code>queryables</code> table is also used to specify which item <code>properties</code> attributes to add indexes on.</p> <p>To add a new global index across all collection partitions:</p> <pre><code>INSERT INTO pgstac.queryables (name, property_wrapper, property_index_type)\nVALUES (&lt;property name&gt;, &lt;property wrapper&gt;, &lt;index type&gt;);\n</code></pre> <p>Property wrapper should be one of <code>to_int</code>, <code>to_float</code>, <code>to_tstz</code>, or <code>to_text</code>. The index type should almost always be <code>BTREE</code>, but can be any PostgreSQL index type valid for the data type.</p> <p>More indexes is note necessarily better. You should only index the primary fields that are actively being used to search. Adding too many indexes can be very detrimental to performance and ingest speed. If your primary use case is delivering items sorted by datetime and you do not use the context extension, you likely will not need any further indexes.</p> <p>Leave <code>property_index_type</code> set to NULL if you do not want an index set for a property.</p>"},{"location":"pgstac/#maintenance-procedures","title":"Maintenance Procedures","text":"<p>These are procedures that should be run periodically to make sure that statistics and constraints are kept up-to-date and validated. These can be made to run regularly using the pg_cron extension if available. <pre><code>SELECT cron.schedule('0 * * * *', 'CALL validate_constraints();');\nSELECT cron.schedule('10, * * * *', 'CALL analyze_items();');\n</code></pre></p>"},{"location":"pypgstac/","title":"pyPgSTAC","text":"<p>PgSTAC includes a Python utility for bulk data loading and managing migrations.</p> <p>PyPGStac is available on PyPI <pre><code>pip install pypgstac\n</code></pre></p> <p>By default, PyPGStac does not install the <code>psycopg</code> dependency. If you want the database driver installed, use:</p> <pre><code>pip install pypgstac[psycopg]\n</code></pre> <p>Or can be built locally <pre><code>git clone https://github.com/stac-utils/pgstac\ncd pgstac/pypgstac\npip install .\n</code></pre></p> <pre><code>pypgstac --help\nUsage: pypgstac [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --install-completion  Install completion for the current shell.\n  --show-completion     Show completion for the current shell, to copy it or\n                        customize the installation.\n\n  --help                Show this message and exit.\n\nCommands:\n  initversion  Get initial version.\n  load         Load STAC data into a pgstac database.\n  migrate      Migrate a pgstac database.\n  pgready      Wait for a pgstac database to accept connections.\n  version      Get version from a pgstac database.\n</code></pre> <p>PyPGStac will get the database connection settings from the standard PG environment variables:</p> <ul> <li>PGHOST=0.0.0.0</li> <li>PGPORT=5432</li> <li>PGUSER=username</li> <li>PGDATABASE=postgis</li> <li>PGPASSWORD=asupersecretpassword</li> </ul> <p>It can also take a DSN database url \"postgresql://...\" via the --dsn flag.</p>"},{"location":"pypgstac/#migrations","title":"Migrations","text":"<p>PyPGStac has a utility to help apply migrations to an existing PGStac instance to bring it up to date.</p> <p>There are two types of migrations:  - Base migrations install PGStac into a database with no current PGStac installation. These migrations follow the file pattern <code>\"pgstac.[version].sql\"</code>  - Incremental migrations are used to move PGStac from one version to the next. These migrations follow the file pattern <code>\"pgstac.[version].[fromversion].sql\"</code></p> <p>Migrations are stored in <code>pypgstac/pypgstac/migration`s</code> and are distributed with the PyPGStac package.</p>"},{"location":"pypgstac/#running-migrations","title":"Running Migrations","text":"<p>PyPGStac has a utility for checking the version of an existing PGStac database and applying the appropriate migrations in the correct order. It can also be used to setup a database from scratch.</p> <p>To create an initial PGStac database or bring an existing one up to date, check you have the pypgstac version installed you want to migrate to and run: <pre><code>pypgstac migrate\n</code></pre></p>"},{"location":"pypgstac/#bulk-data-loading","title":"Bulk Data Loading","text":"<p>A python utility is included which allows to load data from any source openable by smart-open using python in a memory efficient streaming manner using PostgreSQL copy. There are options for collections and items and can be used either as a command line or a library.</p> <p>To load an ndjson of items directly using copy (will fail on any duplicate ids but is the fastest option to load new data you know will not conflict) <pre><code>pypgstac load items\n</code></pre></p> <p>To load skipping any records that conflict with existing data <pre><code>pypgstac load items --method insert_ignore\n</code></pre></p> <p>To upsert any records, adding anything new and replacing anything with the same id <pre><code>pypgstac load items --method upsert\n</code></pre></p>"},{"location":"release-notes/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog and this project adheres to Semantic Versioning.</p>"},{"location":"release-notes/#v0710","title":"[v0.7.10]","text":""},{"location":"release-notes/#fixed","title":"Fixed","text":"<ul> <li>Return an empty jsonb array from all_collections() when the collections table is empty, instead of NULL. Fixes #186.</li> <li>Add delete trigger to collections to clean up partition_stats records and remove any partitions. Fixes #185</li> <li>Fixes boolean casting in get_setting_bool function</li> </ul>"},{"location":"release-notes/#v079","title":"[v0.7.9]","text":""},{"location":"release-notes/#fixed_1","title":"Fixed","text":"<ul> <li>Update docker image to use postgis 3.3.3</li> </ul>"},{"location":"release-notes/#v078","title":"[v0.7.8]","text":""},{"location":"release-notes/#fixed_2","title":"Fixed","text":"<ul> <li>Fix issue with search_query not returning all fields on first use of a query. Fixes #182</li> </ul>"},{"location":"release-notes/#v077","title":"[v0.7.7]","text":""},{"location":"release-notes/#fixed_3","title":"Fixed","text":"<ul> <li>Fix migrations for 0.7.4-&gt;0.7.5 and 0.7.5-&gt;0.7.6 to use the partition_view rather than the materialized view to avoid issue with refreshing the materialized view when run in the same statement that is accessing the view. Fixes #180.</li> </ul>"},{"location":"release-notes/#added","title":"Added","text":"<ul> <li>Add a short cirucit for id searches that sets the limit to be no more than the number of ids in the filter.</li> <li>Add 'timing' configuration variable that adds a \"timing\" element to the return object with the amount of time that it took to return a search.</li> <li>Reduce locking when updating statistics in the search table. Use skip locked to skip updating last_used and count when there is a lock being held.</li> </ul>"},{"location":"release-notes/#v076","title":"[v0.7.6]","text":""},{"location":"release-notes/#fixed_4","title":"Fixed","text":"<ul> <li>Fix issue with checking for existing collections in queryable trigger function that prevented adding scoped queryable entries.</li> </ul>"},{"location":"release-notes/#v075","title":"[v0.7.5]","text":""},{"location":"release-notes/#fixed_5","title":"Fixed","text":"<ul> <li>Default sort not getting set when sortby not included in query with token (Fixes #177)</li> <li>Fixes regression in performance between with changes for partition structure at v0.7.0. Changes the normal view for partitions and partition_steps into indexed materialized views. Adds refreshing of the views to existing triggers to make sure they stay up to date.</li> </ul>"},{"location":"release-notes/#v074","title":"[v0.7.4]","text":""},{"location":"release-notes/#added_1","title":"Added","text":"<ul> <li>Add --v and --vv options to scripts/test to change logging to notice / log when running tests.</li> <li>Add framework for option to cache expensive item formatting/hydrating calls. Note: this only provides functionality to add and read from the cached calls, but does not have any wiring to remove any entries from the cache.</li> <li>Update the costs for json formatting functions to 5000 to help the query planner choose to prefer using indexes on json fields.</li> </ul>"},{"location":"release-notes/#fixed_6","title":"Fixed","text":"<ul> <li>Fix bug in foreign key and unique collection detection in queryables trigger function, update tests to catch.</li> <li>Add collection id to tokens to ensure uniqueness and improve speed when looking up token values. Update tests to use the new keys. Old item id only tokens are still valid, but new results will all contain the new keys.</li> <li>Improve performance when looking for whether next/prev links should be added.</li> <li>Update Search function to remove the use of cursors and temp tables.</li> <li>Update get_token_filter to remove the use of temp tables.</li> </ul>"},{"location":"release-notes/#v073","title":"[v0.7.3]","text":""},{"location":"release-notes/#fixed_7","title":"Fixed","text":"<ul> <li>Use IF EXISTS when dropping constraints to avoid race conditions</li> <li>Rework function that finds indexes that need to be added to be added and to find functionally identical indexes better.</li> </ul>"},{"location":"release-notes/#v072","title":"[v0.7.2]","text":""},{"location":"release-notes/#fixed_8","title":"Fixed","text":"<ul> <li>Use version_parser for parsing versions in pypgstac</li> <li>Fix issue with dropping functions/procedures in 0.6.13-&gt;0.7.0 migrations</li> <li>Fix issue with CREATE OR REPLACE TRIGGER on PG 13</li> <li>Fix issue identifying duplicate indexes in maintain_partition_queries function</li> <li>Ensure that pgstac_read role has read permissions to all partitions</li> <li>Fix issue (and add tests) caused by bug in psycopg datetime types not being able to translate 'infinity', '-infinity'</li> </ul>"},{"location":"release-notes/#v071","title":"[v0.7.1]","text":""},{"location":"release-notes/#fixed_9","title":"Fixed","text":"<ul> <li>Fix permission issue when running incremental migrations.</li> <li>Make sure that pypgstac migrate runs in a single transaction</li> <li>Don't try to use concurrently when building indexes by default (this was tripping things up when using with pg_cron)</li> <li>Don't short circuit search for requests with ids (Fixes #159)</li> <li>Fix for issue with pagination when sorting by columns with nulls (Fixes #161 Fixes #152)</li> <li>Fixes issue where duplicate datetime,end_datetime index was being built.</li> <li>Fix bug in pypgstac loader when using delsert option</li> </ul>"},{"location":"release-notes/#added_2","title":"Added","text":"<ul> <li>Add trigger to detect duplicate configurations for name/collection combination in queryables</li> <li>Add trigger to ensure collections added to queryables exist</li> <li>Add tests for queryables triggers</li> <li>Add more tests for different pagination scenarios</li> </ul>"},{"location":"release-notes/#v070","title":"[v0.7.0]","text":""},{"location":"release-notes/#added_3","title":"Added","text":"<ul> <li>Reorganize code base to create clearer separation between pgstac sql code and pypgstac.</li> <li>Move Python tooling to use hatch with all python project configuration in pyproject.toml</li> <li>Rework testing framework to not rely on pypgstac or migrations. This allows to run tests on any code updates without creating a version first. If a new version has been staged, the tests will still run through all incremental migrations to make sure they pass as well.</li> <li>Add pre-commit to run formatting as well as the tests appropriate for which files have changed.</li> <li>Add a query queue to allow for deferred processing of steps that do not change the ability to get results, but enhance performance. The query queue allows to use pg_cron or similar to run tasks that are placed in the queue.</li> <li>Modify triggers to allow the use of the query queue for building indexes, adding constraints that are used solely for constraint exclusion, and updating partition and collection spatial and temporal extents. The use of the queue is controlled by the new configuration parameter \"use_queue\" which can be set as the pgstac.use_queue GUC or by setting in the pgstac_settings table.</li> <li>Reorganize how partitions are created and updated to maintain more metadata about partition extents and better tie the constraints to the actual temporal extent of a partition.</li> <li>Add \"partitions\" view that shows stats about number of records, the partition range, constraint ranges, actual date range and spatial extent of each partition.</li> <li>Add ability to automatically update the extent object on a collection using the partition metadata via triggers. This is controlled by the new configuration parameter \"update_collection_extent\" which can be set as the pgstac.update_collection_extent GUC or by setting in the pgstac_settings table. This can be combined with \"use_queue\" to defer the processing.</li> <li>Add many new tests.</li> <li>Migrations now make sure that all objects in the pgstac schema are owned by the pgstac_admin role. Functions marked as \"SECURITY DEFINER\" have been moved to the lower level functions responsible for creating/altering partitions and adding records to the search/search_wheres tables. This should open the door for approaches to using Row Level Security.</li> <li>Allow pypgstac loader to load data on pgstac databases that have the same major version even if minor version differs. [162] (stac-utils/pgstac#162) Cherry picked from stac-utils/pgstac!164.</li> </ul>"},{"location":"release-notes/#fixed_10","title":"Fixed","text":"<ul> <li>Allow empty strings in datetime intervals</li> <li>Set search_path and application_name upon connection rather than as kwargs for compatibility with RDS [156] (stac-utils/pgstac#156)</li> </ul>"},{"location":"release-notes/#v0613","title":"[v0.6.13]","text":""},{"location":"release-notes/#fixed_11","title":"Fixed","text":"<ul> <li>Fix issue with sorting and paging where in some circumstances the aggregation of data changed the expected order</li> </ul>"},{"location":"release-notes/#v0612","title":"[v0.6.12]","text":""},{"location":"release-notes/#added_4","title":"Added","text":"<ul> <li>Add ability to merge enum, min, and max from queryables where collections have different values.</li> <li>Add tooling in pypgstac and pgstac to add stac_extension definitions to the database.</li> <li>Modify missing_queryables function to try to use stac_extension definitions to populate queryable definitions from the stac_extension schemas.</li> <li>Add validate_constraints procedure</li> <li>Add analyze_items procedure</li> <li>Add check_pgstac_settings function to check system and pgstac settings.</li> </ul>"},{"location":"release-notes/#fixed_12","title":"Fixed","text":"<ul> <li>Fix issue with upserts in the trigger for using the items_staging tables</li> <li>Fix for generating token query for sorting. [152] (stac-utils/pgstac!152)</li> </ul>"},{"location":"release-notes/#v0611","title":"[v0.6.11]","text":""},{"location":"release-notes/#fixed_13","title":"Fixed","text":"<ul> <li>update pypgstac requirements to support python 3.11 142</li> <li>rename pgstac setting <code>default-filter-lang</code> to <code>default_filter_lang</code> to allow pgstac on postgresql&gt;=14</li> </ul>"},{"location":"release-notes/#v0610","title":"v0.6.10","text":""},{"location":"release-notes/#fixed_14","title":"Fixed","text":"<ul> <li>Makes sure that passing in a non-existing collection does not return a queryable object.</li> </ul>"},{"location":"release-notes/#v069","title":"v0.6.9","text":""},{"location":"release-notes/#fixed_15","title":"Fixed","text":"<ul> <li>Set cursor_tuple_fraction to 1 in search function to let query planner know to expect the entire table result within the search function to be returned. The default cursor_tuple_fraction of .1 within that function was at times creating bad query plans leading to slow queries.</li> </ul>"},{"location":"release-notes/#v068","title":"v0.6.8","text":""},{"location":"release-notes/#added_5","title":"Added","text":"<ul> <li>Add get_queryables function to return a composite queryables json for either a single collection (text), a list of collections(text[]), or for the full repository (null::text).</li> <li>Add missing_queryables(collection text, tablesample int) function to help identify if there are any properties in a collection without entries in the queryables table. The tablesample parameter is an int &lt;=100 that is the approximate percentage of the collection to scan to look for missing queryables rather than reading every item.</li> <li>Add missing_queryables(tablesample int) function that scans all collections using a sample of records to identify missing queryables.</li> </ul>"},{"location":"release-notes/#v067","title":"v0.6.7","text":""},{"location":"release-notes/#added_6","title":"Added","text":"<ul> <li>Add get_queryables function to return a composite queryables json for either a single collection (text), a list of collections(text[]), or for the full repository (null::text).</li> <li>Add missing_queryables(collection text, tablesample int) function to help identify if there are any properties in a collection without entries in the queryables table. The tablesample parameter is an int &lt;=100 that is the approximate percentage of the collection to scan to look for missing queryables rather than reading every item.</li> <li>Add missing_queryables(tablesample int) function that scans all collections using a sample of records to identify missing queryables.</li> </ul>"},{"location":"release-notes/#v066","title":"v0.6.6","text":""},{"location":"release-notes/#added_7","title":"Added","text":"<ul> <li>Add support for array operators in CQL2 (a_equals, a_contains, a_contained_by, a_overlaps).</li> <li>Add check in loader to make sure that pypgstac and pgstac versions match before loading data #123</li> </ul>"},{"location":"release-notes/#v065","title":"v0.6.5","text":""},{"location":"release-notes/#fixed_16","title":"Fixed","text":"<ul> <li>Fix for type casting when using the \"in\" operator #122</li> <li>Fix failure of pypgstac load for large items #121</li> </ul>"},{"location":"release-notes/#v064","title":"v0.6.4","text":""},{"location":"release-notes/#fixed_17","title":"Fixed","text":"<ul> <li>Fixed casts for numeric data when a property is not in the queryables table to use the type from the incoming json filter</li> <li>Fixed issue loader grouping an unordered iterable by partition, speeding up loads of items with mixed partitions #116</li> </ul>"},{"location":"release-notes/#v063","title":"v0.6.3","text":""},{"location":"release-notes/#fixed_18","title":"Fixed","text":"<ul> <li>Fixed content_hydrate argument ordering which caused incorrect behavior in database hydration #115</li> </ul>"},{"location":"release-notes/#added_8","title":"Added","text":"<ul> <li>Skip partition updates when unnecessary, which can drastically improve large ingest performance into existing partitions. #114</li> </ul>"},{"location":"release-notes/#v062","title":"v0.6.2","text":""},{"location":"release-notes/#fixed_19","title":"Fixed","text":"<ul> <li>Ensure special keys are not in content when loaded #112</li> </ul>"},{"location":"release-notes/#v061","title":"v0.6.1","text":""},{"location":"release-notes/#fixed_20","title":"Fixed","text":"<ul> <li>Fix issue where using equality operator against an array was only comparing the first element of the array</li> </ul>"},{"location":"release-notes/#v060","title":"v0.6.0","text":""},{"location":"release-notes/#fixed_21","title":"Fixed","text":"<ul> <li>Fix function signatures for transactional functions (delete_item etc) to make sure that they are marked as volatile</li> <li>Fix function for getting start/end dates from a stac item</li> </ul>"},{"location":"release-notes/#changed","title":"Changed","text":"<ul> <li>Update hydration/dehydration logic to make sure that it matches hydration/dehydration in pypgstac</li> <li>Update fields logic in pgstac to only use full paths and to match logic in stac-fastapi</li> <li>Always include id and collection on features regardless of fields setting</li> </ul>"},{"location":"release-notes/#added_9","title":"Added","text":"<ul> <li>Add tests to ensure that pgstac and pypgstac hydration logic is equivalent</li> <li>Add conf item to search to allow returning results without hydrating. This allows an application using pgstac to shift the CPU load of rehydrating items from the database onto the application server.</li> <li>Add \"--dehydrated\" option to loader to be able to load a dehydrated file (or iterable) of items such as would be output using pg_dump or postgresql copy.</li> <li>Add \"--chunksize\" option to loader that can split the processing of an iterable or file into chunks of n records at a time</li> </ul>"},{"location":"release-notes/#v051","title":"v0.5.1","text":""},{"location":"release-notes/#fixed_22","title":"Fixed","text":""},{"location":"release-notes/#changed_1","title":"Changed","text":""},{"location":"release-notes/#added_10","title":"Added","text":"<ul> <li>Add conf item to search to allow returning results without hydrating. This allows an application using pgstac to shift the CPU load of rehydrating items from the database onto the application server.</li> </ul>"},{"location":"release-notes/#v050","title":"v0.5.0","text":"<p>Version 0.5.0 is a major refactor of how data is stored. It is recommended to start a new database from scratch and to move data over rather than to use the inbuilt migration which will be very slow for larger amounts of data.</p>"},{"location":"release-notes/#fixed_23","title":"Fixed","text":""},{"location":"release-notes/#changed_2","title":"Changed","text":"<ul> <li> <p>The partition layout has been changed from being hardcoded to a partition to week to using nested partitions. The first level is by collection, for each collection, there is an attribute partition_trunc which can be set to NULL (no temporal partitions), month, or year.</p> </li> <li> <p>CQL1 and Query Code have been refactored to translate to CQL2 to reduce duplicated code in query parsing.</p> </li> <li> <p>Unused functions have been stripped from the project.</p> </li> <li> <p>Pypgstac has been changed to use Fire rather than Typo.</p> </li> <li> <p>Pypgstac has been changed to use Psycopg3 rather than Asyncpg to enable easier use as both sync and async.</p> </li> <li> <p>Indexing has been reworked to eliminate indexes that from logs were not being used. The global json index on properties has been removed. Indexes on individual properties can be added either globally or per collection using the new queryables table.</p> </li> <li> <p>Triggers for maintaining partitions have been updated to reduce lock contention and to reflect the new data layout.</p> </li> <li> <p>The data pager which optimizes \"order by datetime\" searches has been updated to get time periods from the new partition layout and partition metadata.</p> </li> <li> <p>Tests have been updated to reflect the many changes.</p> </li> </ul>"},{"location":"release-notes/#added_11","title":"Added","text":"<ul> <li>On ingest, the content in an item is compared to the metadata available at the collection level and duplicate information is stripped out (this is primarily data in the item_assets property). Logic is added in to merge this data back in on data usage.</li> </ul>"},{"location":"release-notes/#v045","title":"v0.4.5","text":""},{"location":"release-notes/#fixed_24","title":"Fixed","text":"<ul> <li>Fixes support for using the intersects parameter at the base of a search (regression from changes in 0.4.4)</li> <li>Fixes issue where results for a search on id returned [None] rather than [] (regression from changes in 0.4.4)</li> </ul>"},{"location":"release-notes/#changed_3","title":"Changed","text":"<ul> <li>Changes requirement for PostgreSQL to 13+, the triggers used to main partitions are not available to be used on partitions prior to 13 (#90)</li> <li>Bump requirement for asyncpg to 0.25.0 (#82)</li> </ul>"},{"location":"release-notes/#added_12","title":"Added","text":"<ul> <li>Added more tests.</li> </ul>"},{"location":"release-notes/#v044","title":"v0.4.4","text":""},{"location":"release-notes/#added_13","title":"Added","text":"<ul> <li>Adds support for using ids, collections, datetime, bbox, and intersects parameters separated from the filter-lang (Fixes #85)</li> <li>Previously use of these parameters was translated into cql-json and then to SQL, so was not available when using cql2-json</li> <li>The deprecated query parameter is still only available when filter-lang is set to cql-json</li> </ul>"},{"location":"release-notes/#changed_4","title":"Changed","text":"<ul> <li>Add PLPGSQL for item lookups by id so that the query plan for the simple query can be cached</li> <li>Use item_by_id function when looking up records used for paging filters</li> <li>Add a short circuit to search to use item_by_id lookup when using the ids parameter<ul> <li>This short circuit avoids using the query cache for this simple case</li> <li>Ordering when using the ids parameter is hard coded to return results in the same order as the array passed in (this avoids the overhead of full parsing and additional overhead to sort)</li> </ul> </li> </ul>"},{"location":"release-notes/#fixed_25","title":"Fixed","text":"<ul> <li>Fix to make sure that filtering on the search_wheres table leverages the functional index on the hash of the query rather than on the query itself.</li> </ul>"},{"location":"release-notes/#v043","title":"v0.4.3","text":""},{"location":"release-notes/#fixed_26","title":"Fixed","text":"<ul> <li>Fix for optimization when using equals with json properties. Allow optimization for both \"eq\" and \"=\" (was only previously enabled for \"eq\")</li> </ul>"},{"location":"release-notes/#v042","title":"v0.4.2","text":""},{"location":"release-notes/#changed_5","title":"Changed","text":"<ul> <li>Add support for updated CQL2 spec to use timestamp or interval key</li> </ul>"},{"location":"release-notes/#fixed_27","title":"Fixed","text":"<ul> <li>Fix for 0.3.4 -&gt; 0.3.5 migration making sure that partitions get renamed correctly</li> </ul>"},{"location":"release-notes/#v041","title":"v0.4.1","text":""},{"location":"release-notes/#changed_6","title":"Changed","text":"<ul> <li>Update <code>typer</code> to 0.4.0 to avoid clashes with <code>click</code> (#76)</li> </ul>"},{"location":"release-notes/#fixed_28","title":"Fixed","text":"<ul> <li>Fix logic in getting settings to make sure that filter-lang set on query is respected. (#77)</li> <li>Fix for large queries in the query cache. (#71)</li> </ul>"},{"location":"release-notes/#v040","title":"v0.4.0","text":""},{"location":"release-notes/#fixed_29","title":"Fixed","text":"<ul> <li>Fixes syntax for IN, BETWEEN, ISNULL, and NOT in CQL 1 (#69)</li> </ul>"},{"location":"release-notes/#added_14","title":"Added","text":"<ul> <li>Adds support for modifying settings through pgstac_settings table and by passing in 'conf' object in search json to support AWS RDS where custom user configuration settings are not allowed and changing settings on the fly for a given query.</li> <li>Adds support for CQL2-JSON (#67)</li> <li>Adds tests for all examples in github.com/radiantearth/stac-api-spec/blob/f5da775080ff3ff46d454c2888b6e796ee956faf/fragments/filter/README.md</li> <li>filter-lang parameter controls which dialect of CQL to use<ul> <li>Adds 'default-filter-lang' setting to control what dialect to use when 'filter-lang' is not present</li> <li>old style stac 'query' object and top level ids, collections, datetime, bbox, and intersects parameters are only available with cql-json</li> </ul> </li> </ul>"},{"location":"release-notes/#v034","title":"v0.3.4","text":""},{"location":"release-notes/#added_15","title":"Added","text":"<ul> <li>add <code>geometrysearch</code>, <code>geojsonsearch</code> and <code>xyzsearch</code> for optimized searches for tiled requets (#39)</li> <li>add <code>create_items</code> and <code>upsert_items</code> methods for bulk insert (#39)</li> </ul>"},{"location":"release-notes/#v033","title":"v0.3.3","text":""},{"location":"release-notes/#fixed_30","title":"Fixed","text":"<ul> <li>Fixed CQL term to be \"id\", not \"ids\" (#46)</li> <li>Make sure featureCollection response has empty features <code>[]</code> not <code>null</code> (#46)</li> <li>Fixed bugs for <code>sortby</code> and <code>pagination</code> (#46)</li> <li>Make sure pgtap errors get caught in CI (#46)</li> </ul>"},{"location":"release-notes/#v032","title":"v0.3.2","text":""},{"location":"release-notes/#fixed_31","title":"Fixed","text":"<ul> <li>Fixed CQL term to be \"collections\", not \"collection\" (#43)</li> </ul>"},{"location":"release-notes/#v031","title":"v0.3.1","text":"<p>TODO</p>"},{"location":"release-notes/#v028","title":"v0.2.8","text":""},{"location":"release-notes/#added_16","title":"Added","text":"<ul> <li>Type hints to pypgstac that pass mypy checks (#18)</li> </ul>"},{"location":"release-notes/#fixed_32","title":"Fixed","text":"<ul> <li>Fixed issue with pypgstac loads which caused some writes to fail (#18)</li> </ul>"}]}